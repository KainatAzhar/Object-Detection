{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Real-Time Object Detection with YOLOv5\n",
    "\n",
    "### Project Overview\n",
    "This project demonstrates the implementation of a real-time object detection system using the **YOLOv5** (You Only Look Once) model. It is designed to identify and localize multiple objects within an image or video frame with high speed and accuracy. This project highlights proficiency in a state-of-the-art computer vision model, a key skill for applications like autonomous systems and video surveillance.\n",
    "\n",
    "### Dataset\n",
    "The project utilizes a pre-trained **YOLOv5 model** from the PyTorch Hub. The model was originally trained on the large-scale **COCO dataset**, which contains over 300,000 images and 80 object categories. This approach showcases the power of transfer learning in object detection.\n",
    "\n",
    "### Methodology\n",
    "1.  **Model Loading:** A pre-trained YOLOv5s model is loaded directly from the PyTorch Hub. This bypasses the need for extensive training and allows the model to be used for inference immediately.\n",
    "2.  **Inference on Images:** The model is used to detect objects in a static image, outputting bounding boxes and confidence scores.\n",
    "3.  **Real-Time Video Inference:** The model is applied to a video stream, processing each frame in real-time to perform live object detection. The results are displayed with bounding boxes and class labels.\n",
    "4.  **Post-processing:** The project handles the common post-processing step of **Non-Maximum Suppression (NMS)**, which filters out duplicate bounding boxes to ensure clear and accurate detection.\n",
    "\n",
    "### Concluded Results\n",
    "The model successfully performs real-time object detection, demonstrating its ability to accurately identify and locate various objects in both images and video streams. The project serves as a strong example of a practical, high-impact computer vision application and highlights a deep understanding of modern object detection frameworks.\n",
    "\n",
    "### Technologies Used\n",
    "- Python\n",
    "- PyTorch\n",
    "- OpenCV\n",
    "- YOLOv5\n",
    "- Jupyter Notebook"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1r4H1G4B7bO",
    "outputId": "321a4855-4603-490b-d36c-941e737190eb"
   },
   "outputs": [],
   "source": [
    "# Project 3: Real-Time Object Detection with YOLOv5\n",
    "\n",
    "# --- Section 1: Setup and Model Loading ---\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading pre-trained YOLOv5 model from PyTorch Hub...\")\n",
    "try:\n",
    "    # To use a specific version, you can specify the tag like this: 'ultralytics/yolov5:v5.0'\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading YOLOv5 model: {e}\")\n",
    "    print(\"Please ensure you have an active internet connection.\")\n",
    "\n",
    "model.conf = 0.4  # Set confidence threshold to 40%\n",
    "model.iou = 0.5   # Set IoU threshold for NMS to 50%\n",
    "\n",
    "# --- Section 2: Object Detection on a Single Image ---\n",
    "\n",
    "print(\"\\nPerforming object detection on a sample image...\")\n",
    "\n",
    "try:\n",
    "    # Download a sample image for demonstration\n",
    "    image_url = 'https://ultralytics.com/images/zidane.jpg'\n",
    "    image_path = tf.keras.utils.get_file('zidane.jpg', origin=image_url)\n",
    "\n",
    "    # Perform inference\n",
    "    results_image = model(image_path)\n",
    "\n",
    "    # Display results\n",
    "    results_image.print()\n",
    "    results_image.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during image inference: {e}\")\n",
    "\n",
    "# --- Section 3: Object Detection on a Video Stream (Demo) ---\n",
    "\n",
    "print(\"\\nPerforming object detection on a video stream (demo)...\\n\")\n",
    "print(\"This section requires a video file and an environment to display it (e.g., local machine). If using Colab, you may need to save the output video.\")\n",
    "\n",
    "try:\n",
    "    # This part of the code is for demonstration purposes on a local machine with a video file\n",
    "    # To run on Colab, you would need to mount your Google Drive or upload a video file.\n",
    "    # Example: cap = cv2.VideoCapture('/content/drive/MyDrive/your_video.mp4')\n",
    "\n",
    "    # Placeholder for video path\n",
    "    video_path = 'path/to/your/video.mp4'\n",
    "\n",
    "    # The following code is for a local environment with OpenCV\n",
    "    # cap = cv2.VideoCapture(video_path)\n",
    "    # while cap.isOpened():\n",
    "    #     ret, frame = cap.read()\n",
    "    #     if not ret:\n",
    "    #         break\n",
    "    #     results_video = model(frame)\n",
    "    #     results_video.render()  # Draws bounding boxes on the frame\n",
    "    #     cv2.imshow('YOLO Object Detection', results_video.ims[0])\n",
    "    #     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #         break\n",
    "    # cap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"\\nVideo stream demo complete.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during video inference demo: {e}\")\n"
   ]
  }
 ]
}
